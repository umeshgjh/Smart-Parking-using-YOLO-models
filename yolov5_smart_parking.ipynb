{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5uLDH4uzAp",
        "outputId": "6964ffb8-542d-44d1-fdd5-5444490c83d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16531, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 16531 (delta 1), reused 5 (delta 0), pack-reused 16522\u001b[K\n",
            "Receiving objects: 100% (16531/16531), 15.05 MiB | 23.29 MiB/s, done.\n",
            "Resolving deltas: 100% (11354/11354), done.\n",
            "/content/yolov5\n",
            "HEAD is now at 064365d8 Update parse_opt() in export.py to work as in train.py (#10789)\n"
          ]
        }
      ],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 064365d8683fd002e9ad789c1e91fa3d021b44f0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "9f642ec1-2511-41d3-e048-044e98ec5e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.2.1+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDeebwqS9JbZ"
      },
      "source": [
        "## Step 6: Download a Dataset\n",
        "\n",
        "Add your Roboflow API key below to download the default money counting dataset. Alternatively, use the code provided by the Roboflow dashboard in the above step to load a custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knxi2ncxWffW",
        "outputId": "722aac8c-3b79-4a6e-c2a0-2fbfa322024c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.27)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_PhK1oqwQA",
        "outputId": "6b3ea848-1e20-415c-ce7d-c0f1a3b0e034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3DmmGQztJj",
        "outputId": "008e83e7-b923-43da-f372-60525a0503b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- Car\n",
            "- Vacant\n",
            "nc: 2\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: smart_parking\n",
            "  url: https://universe.roboflow.com/smartparking-tijv5/smart_parking/dataset/2\n",
            "  version: 2\n",
            "  workspace: smartparking-tijv5\n",
            "test: ../test/images\n",
            "train: SMART_PARKING-2/train/images\n",
            "val: SMART_PARKING-2/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rvt5wilnDyX",
        "outputId": "7fa9d09b-e759-48ec-d55d-d0307475493e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "#this is the model configuration we will use for our tutorial\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "9ba66c0a-da0a-4f0c-b795-6a627c2b4c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-04-14 06:54:13.972032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-14 06:54:13.972091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-14 06:54:13.973904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-14 06:54:15.142068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5s.yaml, data=/content/yolov5/SMART_PARKING-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=37, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 226 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 üöÄ v7.0-72-g064365d8 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5s summary: 233 layers, 7257791 parameters, 7257791 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/SMART_PARKING-2/train/labels.cache... 1051 images, 6 backgrounds, 0 corrupt: 100% 1051/1051 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB ram): 100% 1051/1051 [00:07<00:00, 138.99it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/SMART_PARKING-2/valid/labels.cache... 288 images, 1 backgrounds, 0 corrupt: 100% 288/288 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 288/288 [00:03<00:00, 72.09it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.40 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/yolov5s_results3/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results3\u001b[0m\n",
            "Starting training for 37 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/36      1.68G     0.1053     0.1768     0.0273        320        416: 100% 66/66 [00:34<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:15<00:00,  1.74s/it]\n",
            "                   all        288       6643      0.029      0.383      0.021    0.00478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/36      1.98G    0.09672     0.1768    0.02417        252        416: 100% 66/66 [00:21<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/9 [00:00<?, ?it/s]WARNING ‚ö†Ô∏è NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:14<00:00,  1.65s/it]\n",
            "                   all        288       6643     0.0196       0.25     0.0356     0.0103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/36      1.98G    0.08728     0.1591    0.02215        446        416: 100% 66/66 [00:21<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:13<00:00,  1.55s/it]\n",
            "                   all        288       6643      0.569      0.171     0.0446     0.0111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/36      1.98G    0.07778     0.1437    0.02151        296        416: 100% 66/66 [00:21<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  11% 1/9 [00:02<00:16,  2.07s/it]WARNING ‚ö†Ô∏è NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:15<00:00,  1.71s/it]\n",
            "                   all        288       6643      0.639      0.279      0.137     0.0443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/36      1.98G    0.07166     0.1347    0.02112        456        416: 100% 66/66 [00:27<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:09<00:00,  1.07s/it]\n",
            "                   all        288       6643      0.385      0.532       0.42      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/36      1.98G    0.06534     0.1303    0.02066        194        416: 100% 66/66 [00:22<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.31it/s]\n",
            "                   all        288       6643      0.656      0.604      0.613      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/36      1.98G    0.06262     0.1281    0.02069        259        416: 100% 66/66 [00:22<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  1.97it/s]\n",
            "                   all        288       6643      0.724      0.677      0.674       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/36      1.98G    0.05871     0.1192     0.0207        200        416: 100% 66/66 [00:21<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.16it/s]\n",
            "                   all        288       6643      0.668       0.67      0.662      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/36      1.98G    0.05599     0.1108    0.02088        282        416: 100% 66/66 [00:20<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.21it/s]\n",
            "                   all        288       6643      0.963      0.375      0.445      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/36      1.98G    0.05658      0.112    0.02075        305        416: 100% 66/66 [00:20<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.00it/s]\n",
            "                   all        288       6643      0.748      0.654      0.698      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/36      1.98G    0.05115     0.1128    0.02027        275        416: 100% 66/66 [00:21<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.14it/s]\n",
            "                   all        288       6643      0.816      0.664      0.713      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/36      1.98G    0.05217     0.1126    0.01998        304        416: 100% 66/66 [00:21<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.25it/s]\n",
            "                   all        288       6643      0.784      0.665      0.695      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/36      1.98G     0.0502     0.1073    0.01959        261        416: 100% 66/66 [00:21<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.10it/s]\n",
            "                   all        288       6643      0.743      0.543      0.606       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/36      1.98G    0.04844     0.1061    0.02003        234        416: 100% 66/66 [00:21<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  1.96it/s]\n",
            "                   all        288       6643      0.823      0.665      0.732      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/36      1.98G    0.04713     0.1031    0.01975        209        416: 100% 66/66 [00:21<00:00,  3.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.11it/s]\n",
            "                   all        288       6643       0.83       0.67      0.754      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/36      1.98G    0.04714     0.1017    0.01989        468        416: 100% 66/66 [00:21<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.03it/s]\n",
            "                   all        288       6643      0.823       0.66      0.732      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/36      1.98G    0.04678      0.104    0.01959        241        416: 100% 66/66 [00:21<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.43it/s]\n",
            "                   all        288       6643      0.813      0.684      0.749      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/36      1.98G    0.04588     0.1016    0.01894        273        416: 100% 66/66 [00:21<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.25it/s]\n",
            "                   all        288       6643       0.82      0.683      0.771      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/36      1.98G     0.0444    0.09932    0.01898        231        416: 100% 66/66 [00:22<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:04<00:00,  2.15it/s]\n",
            "                   all        288       6643      0.815      0.687      0.773      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/36      1.98G    0.04453    0.09456    0.01962        279        416: 100% 66/66 [00:21<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.41it/s]\n",
            "                   all        288       6643      0.832      0.671      0.722      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/36      1.98G    0.04432     0.0959    0.01929        479        416: 100% 66/66 [00:22<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.51it/s]\n",
            "                   all        288       6643      0.794      0.703      0.772      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/36      1.98G    0.04309     0.0965    0.01913        299        416: 100% 66/66 [00:22<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.58it/s]\n",
            "                   all        288       6643      0.811      0.693      0.768      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/36      1.98G     0.0425    0.09291    0.01876        215        416: 100% 66/66 [00:21<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.27it/s]\n",
            "                   all        288       6643      0.838      0.685      0.758      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/36      1.98G    0.04286      0.101    0.01906        223        416: 100% 66/66 [00:22<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.37it/s]\n",
            "                   all        288       6643      0.812       0.71      0.801      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/36      1.98G    0.04149    0.09137    0.01841        194        416: 100% 66/66 [00:22<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.78it/s]\n",
            "                   all        288       6643      0.862      0.703      0.794      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/36      1.98G    0.04088    0.08846    0.01869        372        416: 100% 66/66 [00:22<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.57it/s]\n",
            "                   all        288       6643      0.817      0.696      0.782      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/36      1.98G    0.04105    0.09541    0.01917        279        416: 100% 66/66 [00:23<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.80it/s]\n",
            "                   all        288       6643      0.813      0.682      0.758      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/36      1.98G    0.04023     0.0905    0.01838        252        416: 100% 66/66 [00:22<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.64it/s]\n",
            "                   all        288       6643      0.856      0.666      0.757      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/36      1.98G    0.04088    0.09279    0.01908        477        416: 100% 66/66 [00:22<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.77it/s]\n",
            "                   all        288       6643      0.835      0.692      0.792      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/36      1.98G     0.0404    0.09095    0.01865        317        416: 100% 66/66 [00:22<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.59it/s]\n",
            "                   all        288       6643      0.841      0.684      0.799      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/36      1.98G    0.03977    0.08994    0.01877        330        416: 100% 66/66 [00:22<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.83it/s]\n",
            "                   all        288       6643      0.841      0.681      0.785       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/36      1.98G    0.03857    0.08566    0.01851        224        416: 100% 66/66 [00:22<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.69it/s]\n",
            "                   all        288       6643      0.825      0.689      0.785      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/36      1.98G    0.03849    0.08874    0.01812        447        416: 100% 66/66 [00:22<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.67it/s]\n",
            "                   all        288       6643      0.845      0.682      0.799      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/36      1.98G    0.03805    0.08807    0.01881        348        416: 100% 66/66 [00:22<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.80it/s]\n",
            "                   all        288       6643      0.829      0.698      0.811      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/36      1.98G    0.03747    0.08312    0.01847        171        416: 100% 66/66 [00:22<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.70it/s]\n",
            "                   all        288       6643      0.809      0.693        0.8      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/36      1.98G    0.03799     0.0833    0.01835        238        416: 100% 66/66 [00:22<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.70it/s]\n",
            "                   all        288       6643      0.833      0.691      0.803      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/36      1.98G    0.03822      0.083    0.01881        279        416: 100% 66/66 [00:22<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:03<00:00,  2.78it/s]\n",
            "                   all        288       6643      0.833      0.682      0.801      0.615\n",
            "\n",
            "37 epochs completed in 0.291 hours.\n",
            "Optimizer stripped from runs/train/yolov5s_results3/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/yolov5s_results3/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/yolov5s_results3/weights/best.pt...\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7249215 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  22% 2/9 [00:07<00:29,  4.17s/it]WARNING ‚ö†Ô∏è NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:36<00:00,  4.05s/it]\n",
            "                   all        288       6643      0.846      0.681      0.796      0.614\n",
            "                   Car        288       4799      0.702      0.801      0.875      0.691\n",
            "                Vacant        288       1844      0.991      0.561      0.717      0.538\n",
            "Results saved to \u001b[1mruns/train/yolov5s_results3\u001b[0m\n",
            "CPU times: user 10.3 s, sys: 1.3 s, total: 11.6 s\n",
            "Wall time: 18min 41s\n"
          ]
        }
      ],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 37 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "You can view the training graphs associated with a training job in the `/content/yolov5/runs/train/yolov5s_results/results.png` folder.\n",
        "\n",
        "Training losses and performance metrics are also saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C60XAsyv6OPe",
        "outputId": "6da79281-5919-46ab-fdc8-a8ecca9b7b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CSV file found in the directory: /content/yolov5/runs/train/yolov5s_results/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Locate the directory containing training logs\n",
        "log_dir = '/content/yolov5/runs/train/yolov5s_results/'\n",
        "\n",
        "# Get the list of files in the directory\n",
        "files = os.listdir(log_dir)\n",
        "\n",
        "# Find the CSV file containing training logs\n",
        "csv_files = [file for file in files if file.endswith('.csv')]\n",
        "\n",
        "# Check if any CSV file exists\n",
        "if len(csv_files) == 0:\n",
        "    print(\"No CSV file found in the directory:\", log_dir)\n",
        "else:\n",
        "    # Assuming there's only one CSV file, load the first one\n",
        "    csv_file = csv_files[0]\n",
        "    # Load the training logs\n",
        "    train_logs = pd.read_csv(os.path.join(log_dir, csv_file))\n",
        "\n",
        "    # Extract the desired metrics\n",
        "    metrics = train_logs[['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
        "                          'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP@0.5',\n",
        "                          'metrics/mAP@0.5:0.95', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
        "                          'lr0', 'lr1', 'lr2']]\n",
        "\n",
        "    # Print the metrics\n",
        "    print(metrics)\n",
        "\n",
        "    # Plot the training and validation losses\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(metrics['epoch'], metrics['train/box_loss'], label='Train Box Loss')\n",
        "    plt.plot(metrics['epoch'], metrics['train/cls_loss'], label='Train Class Loss')\n",
        "    plt.plot(metrics['epoch'], metrics['train/dfl_loss'], label='Train DFL Loss')\n",
        "    plt.plot(metrics['epoch'], metrics['val/box_loss'], label='Validation Box Loss')\n",
        "    plt.plot(metrics['epoch'], metrics['val/cls_loss'], label='Validation Class Loss')\n",
        "    plt.plot(metrics['epoch'], metrics['val/dfl_loss'], label='Validation DFL Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Losses')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot the precision, recall, mAP50, and mAP50-95\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(metrics['epoch'], metrics['metrics/precision(B)'], label='Precision')\n",
        "    plt.plot(metrics['epoch'], metrics['metrics/recall(B)'], label='Recall')\n",
        "    plt.plot(metrics['epoch'], metrics['metrics/mAP@0.5'], label='mAP@0.5')\n",
        "    plt.plot(metrics['epoch'], metrics['metrics/mAP@0.5:0.95'], label='mAP@0.5:0.95')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metrics')\n",
        "    plt.title('Precision, Recall, mAP@0.5, and mAP@0.5:0.95')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training logs\n",
        "train_logs = pd.read_csv('/content/yolov5/runs/train/yolov5s_results3/results.csv')\n",
        "\n",
        "# Extract the desired metrics\n",
        "metrics = train_logs[['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
        "                      'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP@0.5',\n",
        "                      'metrics/mAP@0.5:0.95', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
        "                      'lr0', 'lr1', 'lr2']]\n",
        "\n",
        "# Print the metrics\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "FLEIMzNKZYdb",
        "outputId": "4db2cbbe-01c9-4d66-c78e-9db0404bd111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\\n       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP@0.5',\\n       'metrics/mAP@0.5:0.95', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\\n       'lr0', 'lr1', 'lr2'],\\n      dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bf446f5f81f2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract the desired metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m metrics = train_logs[['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n\u001b[0m\u001b[1;32m      8\u001b[0m                       \u001b[0;34m'metrics/precision(B)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics/recall(B)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics/mAP@0.5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0;34m'metrics/mAP@0.5:0.95'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val/box_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val/cls_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val/dfl_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\\n       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP@0.5',\\n       'metrics/mAP@0.5:0.95', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\\n       'lr0', 'lr1', 'lr2'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}